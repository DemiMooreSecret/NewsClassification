{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcc52b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re, hashlib, math, time\n",
    "from random import randint, seed\n",
    "seed(1631996)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c945d0",
   "metadata": {},
   "source": [
    "Вбила в поиск \"алгоритмы поиска дубликатов в текстовых данных\"\n",
    "\n",
    "Нашла статью https://habr.com/ru/companies/mts_ai/articles/726012/\n",
    "\n",
    "пошла искать MinHash\n",
    "\n",
    "нашла код https://www.codemotion.com/magazine/backend/fast-document-similarity-in-python-minhashlsh/\n",
    "\n",
    "адоптировала под данные https://www.kaggle.com/datasets/mikhailma/russian-social-media-text-classification\n",
    "\n",
    "которые предварительно почистила : удалила все ссылки, убрала цифры, удалила стоп-слова, провела лемматизацию. Удалила явные дубликаты\n",
    "\n",
    "в код сильно не вникала"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da2e739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class hashFamily:\n",
    "    def __init__(self, i):\n",
    "        self.resultSize = 8 # how many bytes we want back\n",
    "        self.maxLen = 20 # how long can our i be (in decimal)\n",
    "        self.salt = str(i).zfill(self.maxLen)[-self.maxLen:]\n",
    "        \n",
    "    def get_hash_value(self, el_to_hash):\n",
    "        return int(hashlib.sha1(str(el_to_hash).encode('utf-8') + self.salt.encode('utf-8')).hexdigest()[-self.resultSize:], 16)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db7b9157",
   "metadata": {},
   "outputs": [],
   "source": [
    "class shingler:\n",
    "    def __init__(self, k):\n",
    "        \n",
    "        if k > 0:\n",
    "            self.k = int(k)\n",
    "        else:\n",
    "            self.k = 10\n",
    "        \n",
    "    #inner class utility\n",
    "    def process_doc(self, document):\n",
    "        return re.sub(\"( )+|(\\n)+\",\" \",document).lower()\n",
    "    \n",
    "    def get_shingles(self, document):\n",
    "        shingles = set()\n",
    "        document= self.process_doc(document)\n",
    "        for i in range(0, len(document)-self.k+1 ):\n",
    "            shingles.add(document[i:i+self.k])\n",
    "        return shingles\n",
    "    \n",
    "    def get_k(self):\n",
    "        return self.k\n",
    "    \n",
    "    #return sorted hash\n",
    "    def get_hashed_shingles(self, shingles_set):\n",
    "        hash_function = hashFamily(0)\n",
    "        return sorted( {hash_function.get_hash_value(s) for s in shingles_set} )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62bb3374",
   "metadata": {},
   "outputs": [],
   "source": [
    "class minhashSigner:\n",
    "    def __init__(self, sig_size):\n",
    "        self.sig_size=sig_size\n",
    "        self.hash_functions = [hashFamily(randint(0,10000000000)) for i in range(0,sig_size)]\n",
    "    \n",
    "    def compute_set_signature(self, set_):\n",
    "        set_sig = []\n",
    "        for h_funct in self.hash_functions:\n",
    "            min_hash = math.inf\n",
    "            for el in set_:\n",
    "                h = h_funct.get_hash_value(el)\n",
    "                if h < min_hash:\n",
    "                    min_hash = h\n",
    "                \n",
    "            set_sig.append(min_hash)\n",
    "        \n",
    "        return set_sig\n",
    "    \n",
    "    #return a list of lists that can be seen as the signature matrix\n",
    "    def compute_signature_matrix(self, set_list):\n",
    "        signatures = []\n",
    "        for s in set_list:\n",
    "            signatures.append( self.compute_set_signature(s) )\n",
    "            \n",
    "        return signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a097b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class lsh:\n",
    "    def __init__(self, threshold=0.8):\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def get_signature_matrix_bands(self, sig_matrix, bands_nr, sign_len): \n",
    "        #bands_nr = b\n",
    "        #sign_len = n\n",
    "        r = int(sign_len/bands_nr) #number of rows in each band\n",
    "        bands = {} # {band_nr: [col_1,col_2,...]} where col_1 is all the values of Sig(S_i) for band b.\n",
    "        for i in range(0,bands_nr):\n",
    "            bands[i] = []\n",
    "        \n",
    "        # put Subsets of the columns of signature matrix into the appropriate bucket and cosider a column \n",
    "        # as a unique block so that we can hash the entire column.\n",
    "        # Basically a band is a list of element, where each element is a subset of a signature of a given set.\n",
    "        for signature in sig_matrix: \n",
    "            \n",
    "            for i in range(0, bands_nr):\n",
    "                idx = i*r    \n",
    "                bands[i].append(' '.join(str(x) for x in signature[idx:idx+r]) ) \n",
    "                    \n",
    "        return bands\n",
    "\n",
    "    #band is a list \n",
    "    # construct a dictionary {hash(band_column): doc_id that produced this hash}\n",
    "    def get_band_buckets(self, band, hash_funct):\n",
    "        buckets = {}\n",
    "        for doc_id in range(0,len(band)):\n",
    "            value = hash_funct.get_hash_value( band[doc_id] )\n",
    "            if value not in buckets:\n",
    "                buckets[value] = [doc_id]\n",
    "            else:\n",
    "                 buckets[value].append(doc_id)\n",
    "                \n",
    "        return buckets\n",
    "    \n",
    "    def get_candidates_list(self, buckets):\n",
    "        candidates = set()\n",
    "        # buckets is a dictionary containing key=bucket, value= list of doc_ids that hashed to bucket\n",
    "        for bucket,candidate_list in buckets.items():\n",
    "            if len(candidate_list) > 1:\n",
    "                for i in range(0,len(candidate_list)-1):\n",
    "                    for j in range(i+1,len(candidate_list)):  \n",
    "                        pair = tuple(sorted( (candidate_list[i],candidate_list[j]) ))\n",
    "                        candidates.add(pair)\n",
    "                \n",
    "        return candidates #ie a set of couples, each couple is a candidate pair\n",
    "    \n",
    "    def check_candidates(self, candidates_list, threshold, sigs):\n",
    "        similar_docs = set() #set of tuples\n",
    "        # similar_pair is a couple containing doc_ids of documents that hashed to same bucket\n",
    "        for  similar_pair in candidates_list:\n",
    "            #for all the pairs of document in the list check similarity of their signatures\n",
    "            doc_id_1 = similar_pair[0]\n",
    "            doc_id_2 = similar_pair[1]\n",
    "            signature_1 = set(sigs[doc_id_1]) #get the i-th column from signature matrix where i is doc_id in the collision list\n",
    "            signature_2 = set(sigs[doc_id_2])\n",
    "            js = len(signature_1.intersection(signature_2)) /len(signature_1.union(signature_2))\n",
    "            \n",
    "            if js >= threshold:\n",
    "                similar_docs.add( tuple(sorted((doc_id_1,doc_id_2) )) )\n",
    "                        \n",
    "                        \n",
    "        return similar_docs\n",
    "    \n",
    "    def get_similar_items(self, sig_matrix, bands_nr, sign_len):\n",
    "        similar_docs = set()\n",
    "        #divide signature matrix into bands\n",
    "        bands = lsh_instance.get_signature_matrix_bands(sig_matrix,bands_nr,sign_len)\n",
    "        \n",
    "        #for all the bands\n",
    "        for band_id, elements in bands.items():\n",
    "            #produce the buckets for the given band (band_id) with a random hash function\n",
    "            buckets = lsh_instance.get_band_buckets(elements, hash_funct=hashFamily(randint(0,10000000000)))\n",
    "            #Get all the candidate pairs\n",
    "            candidates = lsh_instance.get_candidates_list(buckets)\n",
    "            #Check all candidate pairs' signatures\n",
    "            for sim_tuple in lsh_instance.check_candidates(candidates, self.threshold, sig_matrix):\n",
    "                similar_docs.add( sim_tuple)\n",
    "\n",
    "        return similar_docs #return all the similar signatures that respect the threshold\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "076e6fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemmas_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12073</th>\n",
       "      <td>международный федерация шахматы фиде объявить ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19379</th>\n",
       "      <td>приветствовать ставить штатный пружина сцеплен...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31389</th>\n",
       "      <td>друг обратить внимание сделать футболка символ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26252</th>\n",
       "      <td>рождение тахир свой рождение отмечать нападать...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25310</th>\n",
       "      <td>внимание игрок гость ярославль комуса фест дат...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           lemmas_string\n",
       "12073  международный федерация шахматы фиде объявить ...\n",
       "19379  приветствовать ставить штатный пружина сцеплен...\n",
       "31389  друг обратить внимание сделать футболка символ...\n",
       "26252  рождение тахир свой рождение отмечать нападать...\n",
       "25310  внимание игрок гость ярославль комуса фест дат..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=pd.read_csv(\"Data/x_train.csv\", index_col=0)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa2bcbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded correctly.\n",
      "Producing Shingles...\n",
      "Shingles produced in:\t 25.52 seconds.\n",
      "Computing signature matrix...\n",
      "Signature Matrix computed in:\t 918.09 seconds.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset...\")\n",
    "dataset=pd.read_csv(\"Data/x_train.csv\", index_col=0)\n",
    "dataset['doc_id']=dataset.index\n",
    "doc_nr = dataset['doc_id'].max()\n",
    "print(\"Dataset loaded correctly.\")\n",
    "print(\"Producing Shingles...\")\n",
    "start_time = time.time()\n",
    "#an array where the index i represent the document_id and the element shingling_list[i] the hashed shingles for document document_id\n",
    "shingling_list = [None] * (doc_nr +1) \n",
    "shingling_size = 10\n",
    "signature_size = 50\n",
    "bands_nr = 10\n",
    "\n",
    "shingler_inst = shingler(shingling_size)\n",
    "signer = minhashSigner(signature_size)\n",
    "\n",
    "\n",
    "#produce hashed shinglings for all documents\n",
    "for index, row in dataset.iterrows():\n",
    "    doc = row['lemmas_string']\n",
    "    i = row['doc_id']\n",
    "    \n",
    "    shinglings = shingler_inst.get_hashed_shingles( shingler_inst.get_shingles(doc) )\n",
    "    shingling_list[i] = shinglings\n",
    "\n",
    "end_time = time.time()\n",
    "lt1 = end_time - start_time\n",
    "print(\"Shingles produced in:\\t %.2f seconds.\"%(lt1))\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"Computing signature matrix...\")\n",
    "#produce a signature for each shingle set\n",
    "signature_matrix = signer.compute_signature_matrix( shingling_list )\n",
    "end_time = time.time()\n",
    "lt2 = end_time - start_time\n",
    "print(\"Signature Matrix computed in:\\t %.2f seconds.\" %(lt2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "009dbd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing LSH similarity...\n",
      "LSH Similarity computed in:\t 2.06 seconds.\n",
      "Similar Elements Found: 300\n"
     ]
    }
   ],
   "source": [
    "lsh_instance = lsh(threshold=0.8)\n",
    "start_time = time.time()\n",
    "print(\"Computing LSH similarity...\")\n",
    "lsh_similar_itemset = lsh_instance.get_similar_items(signature_matrix, bands_nr, signature_size)\n",
    "end_time = time.time()\n",
    "lsh_computation_time = end_time - start_time\n",
    "print(\"LSH Similarity computed in:\\t %.2f seconds.\\nSimilar Elements Found: %d\" %(lsh_computation_time,len(lsh_similar_itemset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd34400a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.064232587814331\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "print(lsh_computation_time)\n",
    "print(len(lsh_similar_itemset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b3e7e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['list_similar'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fe3da28",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_similar = 1\n",
    "for i in lsh_similar_itemset:\n",
    "    if dataset.at[i[0], 'list_similar'] == 0 and dataset.at[i[1], 'list_similar'] == 0:\n",
    "        dataset.at[i[0], 'list_similar'] = num_similar\n",
    "        dataset.at[i[1], 'list_similar'] = num_similar\n",
    "        num_similar +=1\n",
    "      \n",
    "    elif dataset.at[i[0], 'list_similar'] == 0 and dataset.at[i[1], 'list_similar'] != 0:\n",
    "        num_old = dataset.at[i[1], 'list_similar']\n",
    "        dataset.at[i[0], 'list_similar'] = num_old\n",
    "    elif dataset.at[i[0], 'list_similar'] != 0 and dataset.at[i[1], 'list_similar'] == 0:\n",
    "        num_old = dataset.at[i[0], 'list_similar']\n",
    "        dataset.at[i[1], 'list_similar'] = num_old\n",
    "    elif dataset.at[i[0], 'list_similar'] < dataset.at[i[1], 'list_similar']:\n",
    "        num_old = dataset.at[i[0], 'list_similar']\n",
    "        dataset.at[i[1], 'list_similar'] = num_old\n",
    "    elif dataset.at[i[0], 'list_similar'] > dataset.at[i[1], 'list_similar']:\n",
    "        num_old = dataset.at[i[1], 'list_similar']\n",
    "        dataset.at[i[0], 'list_similar'] = num_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c29e744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>lemmas_string</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>list_similar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>37290</td>\n",
       "      <td>остаться место успеть внимание болельщик толья...</td>\n",
       "      <td>796</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6595</th>\n",
       "      <td>7198</td>\n",
       "      <td>внимание болельщик тольятти организоваться пое...</td>\n",
       "      <td>6595</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                      lemmas_string  doc_id  \\\n",
       "796        37290  остаться место успеть внимание болельщик толья...     796   \n",
       "6595        7198  внимание болельщик тольятти организоваться пое...    6595   \n",
       "\n",
       "      list_similar  \n",
       "796             29  \n",
       "6595            29  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.query('list_similar==29')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9642e798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "данный алгоритм нашел еще 216 дупликатов за 2.064232587814331\n"
     ]
    }
   ],
   "source": [
    "print(f'данный алгоритм нашел еще {dataset.list_similar.nunique()} дупликатов за {lt1+lt2+lsh_computation_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc046273",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
